{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /Users/serenabaker/opt/anaconda3/lib/python3.8/site-packages (0.0)\r\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /Users/serenabaker/opt/anaconda3/lib/python3.8/site-packages (from sklearn) (0.23.1)\r\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /Users/serenabaker/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.0)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/serenabaker/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.5)\r\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/serenabaker/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.16.0)\r\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/serenabaker/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/serenabaker/opt/anaconda3/lib/python3.8/site-packages (0.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "0              0              0              0              0   54.418383   \n",
       "1              0              1              0              0   19.899140   \n",
       "2              0              1              0              0    1.736952   \n",
       "3              0              0              0              0    2.525592   \n",
       "4              0              0              0              0    4.134435   \n",
       "\n",
       "   koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "0     2.479000e-04    -2.479000e-04   162.513840          0.003520   \n",
       "1     1.490000e-05    -1.490000e-05   175.850252          0.000581   \n",
       "2     2.630000e-07    -2.630000e-07   170.307565          0.000115   \n",
       "3     3.760000e-06    -3.760000e-06   171.595550          0.001130   \n",
       "4     1.050000e-05    -1.050000e-05   172.979370          0.001900   \n",
       "\n",
       "   koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0         -0.003520  ...             -81      4.467           0.064   \n",
       "1         -0.000581  ...            -176      4.544           0.044   \n",
       "2         -0.000115  ...            -174      4.564           0.053   \n",
       "3         -0.001130  ...            -211      4.438           0.070   \n",
       "4         -0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "target = df[\"koi_disposition\"]\n",
    "target_names = [\"CONFIRMED\", \"FALSE POSITIVE\", \"OTHER\"]\n",
    "\n",
    "data = df.drop(\"koi_disposition\", axis=1)\n",
    "feature_names = data.columns\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873481057898499"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908506075768406"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1082612177063831, 'koi_fpflag_co'),\n",
       " (0.1015763950594457, 'koi_fpflag_nt'),\n",
       " (0.0711712991681786, 'koi_fpflag_ss'),\n",
       " (0.05756316234637173, 'koi_model_snr'),\n",
       " (0.04962340588618611, 'koi_prad'),\n",
       " (0.03676597047394771, 'koi_prad_err2'),\n",
       " (0.03519442969272711, 'koi_fpflag_ec'),\n",
       " (0.03389279157088083, 'koi_duration_err1'),\n",
       " (0.03229429805960799, 'koi_duration_err2'),\n",
       " (0.031117081820816, 'koi_steff_err1'),\n",
       " (0.02934662121461936, 'koi_prad_err1'),\n",
       " (0.02643209737953936, 'koi_steff_err2'),\n",
       " (0.022275457277577706, 'koi_duration'),\n",
       " (0.02204909028661767, 'koi_time0bk_err1'),\n",
       " (0.020749614027627268, 'koi_insol_err1'),\n",
       " (0.02037348115661571, 'koi_time0bk_err2'),\n",
       " (0.020056419245262122, 'koi_depth'),\n",
       " (0.019655737900259106, 'koi_impact'),\n",
       " (0.01787971088798216, 'koi_period'),\n",
       " (0.017007228073151182, 'koi_period_err2'),\n",
       " (0.01586059462411828, 'koi_insol'),\n",
       " (0.015610106402076506, 'koi_insol_err2'),\n",
       " (0.014594689199827909, 'koi_period_err1'),\n",
       " (0.014418513536652501, 'koi_teq'),\n",
       " (0.014021115148176274, 'koi_time0bk'),\n",
       " (0.013408823172506362, 'koi_depth_err2'),\n",
       " (0.013014605411134379, 'koi_depth_err1'),\n",
       " (0.012359182223845905, 'ra'),\n",
       " (0.011455345168241758, 'koi_srad_err1'),\n",
       " (0.011131227195211571, 'dec'),\n",
       " (0.010974035832143361, 'koi_kepmag'),\n",
       " (0.01079918041326714, 'koi_slogg_err2'),\n",
       " (0.01039773804501727, 'koi_impact_err2'),\n",
       " (0.010306298491148532, 'koi_impact_err1'),\n",
       " (0.009521913277901911, 'koi_steff'),\n",
       " (0.009152657811012294, 'koi_srad'),\n",
       " (0.00908994567773968, 'koi_slogg'),\n",
       " (0.008604131853890794, 'koi_srad_err2'),\n",
       " (0.008512306038376813, 'koi_slogg_err1'),\n",
       " (0.0034820812439141603, 'koi_tce_plnt_num')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('koi_kepmag', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6991, 39) (6991,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('koi_disposition', axis=1).astype(float)\n",
    "y = df['koi_disposition']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.213961</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>132.56890</td>\n",
       "      <td>0.01070</td>\n",
       "      <td>-0.01070</td>\n",
       "      <td>...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-148.0</td>\n",
       "      <td>4.505</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>284.31454</td>\n",
       "      <td>42.589321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.115003</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>133.97523</td>\n",
       "      <td>0.00469</td>\n",
       "      <td>-0.00469</td>\n",
       "      <td>...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-195.0</td>\n",
       "      <td>4.431</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>289.38351</td>\n",
       "      <td>41.392689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.183182</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>133.21404</td>\n",
       "      <td>0.00752</td>\n",
       "      <td>-0.00752</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>4.421</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>1.084</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>287.97885</td>\n",
       "      <td>42.679359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.089428</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>134.19990</td>\n",
       "      <td>0.01010</td>\n",
       "      <td>-0.01010</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>4.418</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>1.103</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>293.43079</td>\n",
       "      <td>46.692089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.085905</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>182.08162</td>\n",
       "      <td>0.00113</td>\n",
       "      <td>-0.00113</td>\n",
       "      <td>...</td>\n",
       "      <td>177.0</td>\n",
       "      <td>-195.0</td>\n",
       "      <td>4.479</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>296.03342</td>\n",
       "      <td>40.019611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "3867            0.0            0.0            1.0            1.0    2.213961   \n",
       "908             0.0            0.0            0.0            0.0    9.115003   \n",
       "2222            0.0            0.0            0.0            0.0   10.183182   \n",
       "2094            0.0            0.0            0.0            0.0    3.089428   \n",
       "775             0.0            1.0            0.0            0.0    9.085905   \n",
       "\n",
       "      koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "3867         0.000023        -0.000023    132.56890           0.01070   \n",
       "908          0.000051        -0.000051    133.97523           0.00469   \n",
       "2222         0.000098        -0.000098    133.21404           0.00752   \n",
       "2094         0.000034        -0.000034    134.19990           0.01010   \n",
       "775          0.000012        -0.000012    182.08162           0.00113   \n",
       "\n",
       "      koi_time0bk_err2  ...  koi_steff_err1  koi_steff_err2  koi_slogg  \\\n",
       "3867          -0.01070  ...           148.0          -148.0      4.505   \n",
       "908           -0.00469  ...           160.0          -195.0      4.431   \n",
       "2222          -0.00752  ...           104.0          -127.0      4.421   \n",
       "2094          -0.01010  ...            80.0           -86.0      4.418   \n",
       "775           -0.00113  ...           177.0          -195.0      4.479   \n",
       "\n",
       "      koi_slogg_err1  koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2  \\\n",
       "3867           0.084          -0.058     0.823          0.059         -0.088   \n",
       "908            0.070          -0.210     1.028          0.320         -0.137   \n",
       "2222           0.040          -0.120     1.084          0.177         -0.071   \n",
       "2094           0.028          -0.105     1.103          0.175         -0.062   \n",
       "775            0.091          -0.169     0.866          0.210         -0.113   \n",
       "\n",
       "             ra        dec  \n",
       "3867  284.31454  42.589321  \n",
       "908   289.38351  41.392689  \n",
       "2222  287.97885  42.679359  \n",
       "2094  293.43079  46.692089  \n",
       "775   296.03342  40.019611  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 240       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 303\n",
      "Trainable params: 303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=6, activation='relu', input_dim=39))\n",
    "deep_model.add(Dense(units=6, activation='relu'))\n",
    "deep_model.add(Dense(units=3, activation='softmax'))\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "175/175 - 1s - loss: 1.0836 - accuracy: 0.4483\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 2/100\n",
      "175/175 - 0s - loss: 0.9492 - accuracy: 0.5014\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 3/100\n",
      "175/175 - 0s - loss: 0.6446 - accuracy: 0.7246\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 4/100\n",
      "175/175 - 0s - loss: 0.4724 - accuracy: 0.7527\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 5/100\n",
      "175/175 - 0s - loss: 0.4136 - accuracy: 0.7530\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 6/100\n",
      "175/175 - 0s - loss: 0.3970 - accuracy: 0.7623\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 7/100\n",
      "175/175 - 0s - loss: 0.3887 - accuracy: 0.7949\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 8/100\n",
      "175/175 - 0s - loss: 0.3831 - accuracy: 0.7983\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 9/100\n",
      "175/175 - 0s - loss: 0.3788 - accuracy: 0.8106\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 10/100\n",
      "175/175 - 0s - loss: 0.3740 - accuracy: 0.8151\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 11/100\n",
      "175/175 - 0s - loss: 0.3695 - accuracy: 0.8180\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 12/100\n",
      "175/175 - 0s - loss: 0.3635 - accuracy: 0.8197\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 13/100\n",
      "175/175 - 0s - loss: 0.3582 - accuracy: 0.8262\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 14/100\n",
      "175/175 - 0s - loss: 0.3525 - accuracy: 0.8249\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 15/100\n",
      "175/175 - 0s - loss: 0.3498 - accuracy: 0.8274\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 16/100\n",
      "175/175 - 0s - loss: 0.3448 - accuracy: 0.8344\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 17/100\n",
      "175/175 - 0s - loss: 0.3417 - accuracy: 0.8315\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 18/100\n",
      "175/175 - 0s - loss: 0.3377 - accuracy: 0.8367\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 19/100\n",
      "175/175 - 0s - loss: 0.3355 - accuracy: 0.8369\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 20/100\n",
      "175/175 - 0s - loss: 0.3333 - accuracy: 0.8357\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 21/100\n",
      "175/175 - 0s - loss: 0.3301 - accuracy: 0.8432\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 22/100\n",
      "175/175 - 0s - loss: 0.3278 - accuracy: 0.8408\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 23/100\n",
      "175/175 - 0s - loss: 0.3254 - accuracy: 0.8430\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 24/100\n",
      "175/175 - 0s - loss: 0.3267 - accuracy: 0.8398\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 25/100\n",
      "175/175 - 0s - loss: 0.3215 - accuracy: 0.8460\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 26/100\n",
      "175/175 - 0s - loss: 0.3203 - accuracy: 0.8466\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 27/100\n",
      "175/175 - 0s - loss: 0.3195 - accuracy: 0.8462\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 28/100\n",
      "175/175 - 0s - loss: 0.3184 - accuracy: 0.8448\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 29/100\n",
      "175/175 - 0s - loss: 0.3159 - accuracy: 0.8505\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 30/100\n",
      "175/175 - 0s - loss: 0.3135 - accuracy: 0.8500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 31/100\n",
      "175/175 - 0s - loss: 0.3132 - accuracy: 0.8532\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 32/100\n",
      "175/175 - 0s - loss: 0.3113 - accuracy: 0.8546\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 33/100\n",
      "175/175 - 0s - loss: 0.3103 - accuracy: 0.8559\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 34/100\n",
      "175/175 - 0s - loss: 0.3093 - accuracy: 0.8526\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 35/100\n",
      "175/175 - 0s - loss: 0.3072 - accuracy: 0.8566\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 36/100\n",
      "175/175 - 0s - loss: 0.3064 - accuracy: 0.8546\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 37/100\n",
      "175/175 - 0s - loss: 0.3052 - accuracy: 0.8580\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 38/100\n",
      "175/175 - 0s - loss: 0.3051 - accuracy: 0.8600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 39/100\n",
      "175/175 - 0s - loss: 0.3032 - accuracy: 0.8591\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 40/100\n",
      "175/175 - 0s - loss: 0.3019 - accuracy: 0.8591\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 41/100\n",
      "175/175 - 0s - loss: 0.3021 - accuracy: 0.8582\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 42/100\n",
      "175/175 - 0s - loss: 0.3000 - accuracy: 0.8609\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 43/100\n",
      "175/175 - 0s - loss: 0.2991 - accuracy: 0.8619\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 44/100\n",
      "175/175 - 0s - loss: 0.2984 - accuracy: 0.8611\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "175/175 - 0s - loss: 0.2966 - accuracy: 0.8623\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 46/100\n",
      "175/175 - 0s - loss: 0.2958 - accuracy: 0.8639\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 47/100\n",
      "175/175 - 0s - loss: 0.2949 - accuracy: 0.8664\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 48/100\n",
      "175/175 - 0s - loss: 0.2943 - accuracy: 0.8652\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 49/100\n",
      "175/175 - 0s - loss: 0.2941 - accuracy: 0.8625\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 50/100\n",
      "175/175 - 0s - loss: 0.2941 - accuracy: 0.8643\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 51/100\n",
      "175/175 - 0s - loss: 0.2938 - accuracy: 0.8664\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 52/100\n",
      "175/175 - 0s - loss: 0.2922 - accuracy: 0.8677\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 53/100\n",
      "175/175 - 0s - loss: 0.2902 - accuracy: 0.8705\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 54/100\n",
      "175/175 - 0s - loss: 0.2917 - accuracy: 0.8671\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 55/100\n",
      "175/175 - 0s - loss: 0.2904 - accuracy: 0.8709\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 56/100\n",
      "175/175 - 0s - loss: 0.2882 - accuracy: 0.8712\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 57/100\n",
      "175/175 - 0s - loss: 0.2900 - accuracy: 0.8673\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 58/100\n",
      "175/175 - 0s - loss: 0.2877 - accuracy: 0.8691\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 59/100\n",
      "175/175 - 0s - loss: 0.2879 - accuracy: 0.8700\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 60/100\n",
      "175/175 - 0s - loss: 0.2859 - accuracy: 0.8720\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 61/100\n",
      "175/175 - 0s - loss: 0.2869 - accuracy: 0.8714\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 62/100\n",
      "175/175 - 0s - loss: 0.2859 - accuracy: 0.8745\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 63/100\n",
      "175/175 - 0s - loss: 0.2877 - accuracy: 0.8736\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 64/100\n",
      "175/175 - 0s - loss: 0.2846 - accuracy: 0.8734\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 65/100\n",
      "175/175 - 0s - loss: 0.2843 - accuracy: 0.8784\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 66/100\n",
      "175/175 - 0s - loss: 0.2831 - accuracy: 0.8748\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 67/100\n",
      "175/175 - 0s - loss: 0.2838 - accuracy: 0.8741\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 68/100\n",
      "175/175 - 0s - loss: 0.2859 - accuracy: 0.8729\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 69/100\n",
      "175/175 - 0s - loss: 0.2819 - accuracy: 0.8741\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 70/100\n",
      "175/175 - 0s - loss: 0.2841 - accuracy: 0.8734\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 71/100\n",
      "175/175 - 0s - loss: 0.2822 - accuracy: 0.8754\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 72/100\n",
      "175/175 - 0s - loss: 0.2822 - accuracy: 0.8773\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 73/100\n",
      "175/175 - 0s - loss: 0.2806 - accuracy: 0.8775\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 74/100\n",
      "175/175 - 0s - loss: 0.2818 - accuracy: 0.8768\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 75/100\n",
      "175/175 - 0s - loss: 0.2805 - accuracy: 0.8775\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 76/100\n",
      "175/175 - 0s - loss: 0.2823 - accuracy: 0.8764\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 77/100\n",
      "175/175 - 0s - loss: 0.2817 - accuracy: 0.8775\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 78/100\n",
      "175/175 - 0s - loss: 0.2817 - accuracy: 0.8780\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 79/100\n",
      "175/175 - 0s - loss: 0.2819 - accuracy: 0.8748\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 80/100\n",
      "175/175 - 0s - loss: 0.2790 - accuracy: 0.8782\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 81/100\n",
      "175/175 - 0s - loss: 0.2790 - accuracy: 0.8775\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 82/100\n",
      "175/175 - 0s - loss: 0.2796 - accuracy: 0.8780\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 83/100\n",
      "175/175 - 0s - loss: 0.2781 - accuracy: 0.8789\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 84/100\n",
      "175/175 - 0s - loss: 0.2769 - accuracy: 0.8802\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 85/100\n",
      "175/175 - 0s - loss: 0.2777 - accuracy: 0.8838\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 86/100\n",
      "175/175 - 0s - loss: 0.2773 - accuracy: 0.8798\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 87/100\n",
      "175/175 - 0s - loss: 0.2779 - accuracy: 0.8791\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 88/100\n",
      "175/175 - 0s - loss: 0.2765 - accuracy: 0.8789\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "175/175 - 0s - loss: 0.2759 - accuracy: 0.8784\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 90/100\n",
      "175/175 - 0s - loss: 0.2756 - accuracy: 0.8813\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 91/100\n",
      "175/175 - 0s - loss: 0.2758 - accuracy: 0.8814\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 92/100\n",
      "175/175 - 0s - loss: 0.2756 - accuracy: 0.8807\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 93/100\n",
      "175/175 - 0s - loss: 0.2752 - accuracy: 0.8823\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 94/100\n",
      "175/175 - 0s - loss: 0.2756 - accuracy: 0.8816\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 95/100\n",
      "175/175 - 0s - loss: 0.2755 - accuracy: 0.8827\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 96/100\n",
      "175/175 - 0s - loss: 0.2741 - accuracy: 0.8813\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 97/100\n",
      "175/175 - 0s - loss: 0.2742 - accuracy: 0.8822\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 98/100\n",
      "175/175 - 0s - loss: 0.2763 - accuracy: 0.8822\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 99/100\n",
      "175/175 - 0s - loss: 0.2745 - accuracy: 0.8852\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 100/100\n",
      "175/175 - 0s - loss: 0.2733 - accuracy: 0.8852\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8f6c9a85b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "\n",
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 - 0s - loss: 0.2998 - accuracy: 0.8749\n",
      "Deep Neural Network - Loss: 0.29975736141204834, Accuracy: 0.8749106526374817\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/serenabaker/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "encoded_predictions = deep_model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['FALSE POSITIVE' 'FALSE POSITIVE' 'FALSE POSITIVE' 'FALSE POSITIVE'\n",
      " 'CONFIRMED']\n",
      "Actual Labels: ['FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'CANDIDATE']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "deep_model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(deep_model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.860, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.834, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.838, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.835, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.830, total=   0.4s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.860, total=   0.4s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.834, total=   0.4s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.838, total=   0.4s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.835, total=   0.4s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.830, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.860, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.834, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.838, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.835, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.830, total=   0.4s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.860, total=   0.4s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.834, total=   0.4s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.838, total=   0.3s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.835, total=   0.3s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.830, total=   0.4s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.878, total=   0.4s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.869, total=   0.4s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.868, total=   0.5s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.859, total=   0.4s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.857, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.878, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.869, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.868, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.859, total=   0.4s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.857, total=   0.5s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.878, total=   0.5s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.869, total=   0.5s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.868, total=   0.5s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.859, total=   0.4s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.857, total=   0.5s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.878, total=   0.5s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.869, total=   0.4s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.868, total=   0.4s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.859, total=   0.4s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.857, total=   0.4s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.887, total=   0.4s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.873, total=   0.4s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.875, total=   0.4s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.868, total=   0.4s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.864, total=   0.4s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.887, total=   0.4s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.873, total=   0.5s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.875, total=   0.5s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.868, total=   0.5s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.864, total=   0.5s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.887, total=   0.5s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.873, total=   0.5s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.875, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.868, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.864, total=   0.5s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.887, total=   0.5s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.873, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.875, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.868, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.864, total=   0.4s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, gamma=0.0001, score=0.893, total=   0.5s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.879, total=   0.5s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.886, total=   0.5s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.871, total=   0.4s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.881, total=   0.5s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.893, total=   0.5s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.879, total=   0.4s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.886, total=   0.5s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.871, total=   0.4s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.881, total=   0.6s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.893, total=   0.5s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.879, total=   0.4s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.886, total=   0.5s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.871, total=   0.4s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.881, total=   0.6s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.893, total=   0.5s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.879, total=   0.5s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.886, total=   0.5s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.871, total=   0.4s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.881, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   35.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [1, 5, 10, 50],\n",
       "                         'gamma': [0.0001, 0.0005, 0.001, 0.005]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV(estimator=SVC(kernel='linear'),\n",
    "             param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]},\n",
    "             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 50, 'gamma': 0.0001}\n",
      "0.8819727874843531\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FALSE POSITIVE' 'FALSE POSITIVE' 'FALSE POSITIVE' ... 'FALSE POSITIVE'\n",
      " 'FALSE POSITIVE' 'CONFIRMED']\n"
     ]
    }
   ],
   "source": [
    " # Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test_scaled)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.881\n"
     ]
    }
   ],
   "source": [
    "print('Test Acc: %.3f' % grid.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8790899625319256"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "#metrics.f1_score(y_test, predictions, labels=np.unique(predictions))\n",
    "metrics.f1_score(y_test, predictions, average='weighted', labels=np.unique(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CONFIRMED       0.85      0.67      0.75       338\n",
      "FALSE POSITIVE       0.74      0.85      0.79       360\n",
      "         OTHER       0.97      1.00      0.99       701\n",
      "\n",
      "      accuracy                           0.88      1399\n",
      "     macro avg       0.86      0.84      0.84      1399\n",
      "  weighted avg       0.88      0.88      0.88      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"CONFIRMED\", \"FALSE POSITIVE\", \"OTHER\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['serena_baker.sav']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "\n",
    "import joblib\n",
    "filename = 'serena_baker.sav'\n",
    "joblib.dump(deep_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
